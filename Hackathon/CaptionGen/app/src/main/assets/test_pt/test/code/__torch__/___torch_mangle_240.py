class Captioner(Module):
  __parameters__ = []
  __buffers__ = []
  __annotations__ = []
  __annotations__["prepack_folding._jit_pass_packed_weight_0"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_1"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_2"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_3"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_4"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_5"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_6"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_7"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_8"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_9"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_10"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_11"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_12"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_13"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_14"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_15"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_16"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_17"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_18"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_19"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_20"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_21"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_22"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_23"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_24"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_25"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_26"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_27"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_28"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_29"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_30"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_31"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_32"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_33"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_34"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_35"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_36"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_37"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_38"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_39"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_40"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_41"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_42"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_43"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_44"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_45"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_46"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_47"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_48"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_49"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_50"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_51"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_52"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_53"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_54"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_55"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_56"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_57"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_58"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_59"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_60"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_61"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_62"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_63"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_64"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_65"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_66"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_67"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_68"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_69"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_70"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_71"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_72"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_73"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_74"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_75"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_76"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_77"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_78"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_79"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_80"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_81"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_82"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_83"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_84"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_85"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_86"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_87"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_88"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_89"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_90"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_91"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_92"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_93"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_94"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_95"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_96"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_97"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_98"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_99"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_100"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_101"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_102"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_103"] = __torch__.torch.classes.xnnpack.Conv2dOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_104"] = __torch__.torch.classes.xnnpack.LinearOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_105"] = __torch__.torch.classes.xnnpack.LinearOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_106"] = __torch__.torch.classes.xnnpack.LinearOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_107"] = __torch__.torch.classes.xnnpack.LinearOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_108"] = __torch__.torch.classes.xnnpack.LinearOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_109"] = __torch__.torch.classes.xnnpack.LinearOpContext
  __annotations__["prepack_folding._jit_pass_packed_weight_110"] = __torch__.torch.classes.xnnpack.LinearOpContext
  mobile_optimized : bool
  def forward(self: __torch__.___torch_mangle_240.Captioner,
    image: Tensor) -> Tensor:
    _0 = "input has inconsistent input_size: got {}, expected {}"
    _1 = "Input batch size {} doesn\'t match hidden{} batch size {}"
    _2 = "hidden{} has inconsistent hidden_size: got {}, expected {}"
    _3 = uninitialized(int)
    _4 = uninitialized(Tensor)
    _5 = uninitialized(bool)
    _6 = getattr(self, "prepack_folding._jit_pass_packed_weight_0")
    _7 = ops.prepacked.conv2d_clamp_run(image, _6)
    input = torch.max_pool2d(_7, [3, 3], [2, 2], [1, 1], [1, 1], False)
    _8 = getattr(self, "prepack_folding._jit_pass_packed_weight_1")
    _9 = ops.prepacked.conv2d_clamp_run(input, _8)
    _10 = getattr(self, "prepack_folding._jit_pass_packed_weight_2")
    _11 = ops.prepacked.conv2d_clamp_run(_9, _10)
    _12 = getattr(self, "prepack_folding._jit_pass_packed_weight_3")
    out = ops.prepacked.conv2d_clamp_run(_11, _12)
    _13 = getattr(self, "prepack_folding._jit_pass_packed_weight_4")
    identity = ops.prepacked.conv2d_clamp_run(input, _13)
    _14 = torch._add_relu_(out, identity, alpha=1)
    _15 = getattr(self, "prepack_folding._jit_pass_packed_weight_5")
    _16 = ops.prepacked.conv2d_clamp_run(_14, _15)
    _17 = getattr(self, "prepack_folding._jit_pass_packed_weight_6")
    _18 = ops.prepacked.conv2d_clamp_run(_16, _17)
    _19 = getattr(self, "prepack_folding._jit_pass_packed_weight_7")
    out0 = ops.prepacked.conv2d_clamp_run(_18, _19)
    _20 = torch._add_relu_(out0, _14, alpha=1)
    _21 = getattr(self, "prepack_folding._jit_pass_packed_weight_8")
    _22 = ops.prepacked.conv2d_clamp_run(_20, _21)
    _23 = getattr(self, "prepack_folding._jit_pass_packed_weight_9")
    _24 = ops.prepacked.conv2d_clamp_run(_22, _23)
    _25 = getattr(self, "prepack_folding._jit_pass_packed_weight_10")
    out1 = ops.prepacked.conv2d_clamp_run(_24, _25)
    _26 = torch._add_relu_(out1, _20, alpha=1)
    _27 = getattr(self, "prepack_folding._jit_pass_packed_weight_11")
    _28 = ops.prepacked.conv2d_clamp_run(_26, _27)
    _29 = getattr(self, "prepack_folding._jit_pass_packed_weight_12")
    _30 = ops.prepacked.conv2d_clamp_run(_28, _29)
    _31 = getattr(self, "prepack_folding._jit_pass_packed_weight_13")
    out2 = ops.prepacked.conv2d_clamp_run(_30, _31)
    _32 = getattr(self, "prepack_folding._jit_pass_packed_weight_14")
    identity0 = ops.prepacked.conv2d_clamp_run(_26, _32)
    _33 = torch._add_relu_(out2, identity0, alpha=1)
    _34 = getattr(self, "prepack_folding._jit_pass_packed_weight_15")
    _35 = ops.prepacked.conv2d_clamp_run(_33, _34)
    _36 = getattr(self, "prepack_folding._jit_pass_packed_weight_16")
    _37 = ops.prepacked.conv2d_clamp_run(_35, _36)
    _38 = getattr(self, "prepack_folding._jit_pass_packed_weight_17")
    out3 = ops.prepacked.conv2d_clamp_run(_37, _38)
    _39 = torch._add_relu_(out3, _33, alpha=1)
    _40 = getattr(self, "prepack_folding._jit_pass_packed_weight_18")
    _41 = ops.prepacked.conv2d_clamp_run(_39, _40)
    _42 = getattr(self, "prepack_folding._jit_pass_packed_weight_19")
    _43 = ops.prepacked.conv2d_clamp_run(_41, _42)
    _44 = getattr(self, "prepack_folding._jit_pass_packed_weight_20")
    out4 = ops.prepacked.conv2d_clamp_run(_43, _44)
    _45 = torch._add_relu_(out4, _39, alpha=1)
    _46 = getattr(self, "prepack_folding._jit_pass_packed_weight_21")
    _47 = ops.prepacked.conv2d_clamp_run(_45, _46)
    _48 = getattr(self, "prepack_folding._jit_pass_packed_weight_22")
    _49 = ops.prepacked.conv2d_clamp_run(_47, _48)
    _50 = getattr(self, "prepack_folding._jit_pass_packed_weight_23")
    out5 = ops.prepacked.conv2d_clamp_run(_49, _50)
    _51 = torch._add_relu_(out5, _45, alpha=1)
    _52 = getattr(self, "prepack_folding._jit_pass_packed_weight_24")
    _53 = ops.prepacked.conv2d_clamp_run(_51, _52)
    _54 = getattr(self, "prepack_folding._jit_pass_packed_weight_25")
    _55 = ops.prepacked.conv2d_clamp_run(_53, _54)
    _56 = getattr(self, "prepack_folding._jit_pass_packed_weight_26")
    out6 = ops.prepacked.conv2d_clamp_run(_55, _56)
    _57 = getattr(self, "prepack_folding._jit_pass_packed_weight_27")
    identity1 = ops.prepacked.conv2d_clamp_run(_51, _57)
    _58 = torch._add_relu_(out6, identity1, alpha=1)
    _59 = getattr(self, "prepack_folding._jit_pass_packed_weight_28")
    _60 = ops.prepacked.conv2d_clamp_run(_58, _59)
    _61 = getattr(self, "prepack_folding._jit_pass_packed_weight_29")
    _62 = ops.prepacked.conv2d_clamp_run(_60, _61)
    _63 = getattr(self, "prepack_folding._jit_pass_packed_weight_30")
    out7 = ops.prepacked.conv2d_clamp_run(_62, _63)
    _64 = torch._add_relu_(out7, _58, alpha=1)
    _65 = getattr(self, "prepack_folding._jit_pass_packed_weight_31")
    _66 = ops.prepacked.conv2d_clamp_run(_64, _65)
    _67 = getattr(self, "prepack_folding._jit_pass_packed_weight_32")
    _68 = ops.prepacked.conv2d_clamp_run(_66, _67)
    _69 = getattr(self, "prepack_folding._jit_pass_packed_weight_33")
    out8 = ops.prepacked.conv2d_clamp_run(_68, _69)
    _70 = torch._add_relu_(out8, _64, alpha=1)
    _71 = getattr(self, "prepack_folding._jit_pass_packed_weight_34")
    _72 = ops.prepacked.conv2d_clamp_run(_70, _71)
    _73 = getattr(self, "prepack_folding._jit_pass_packed_weight_35")
    _74 = ops.prepacked.conv2d_clamp_run(_72, _73)
    _75 = getattr(self, "prepack_folding._jit_pass_packed_weight_36")
    out9 = ops.prepacked.conv2d_clamp_run(_74, _75)
    _76 = torch._add_relu_(out9, _70, alpha=1)
    _77 = getattr(self, "prepack_folding._jit_pass_packed_weight_37")
    _78 = ops.prepacked.conv2d_clamp_run(_76, _77)
    _79 = getattr(self, "prepack_folding._jit_pass_packed_weight_38")
    _80 = ops.prepacked.conv2d_clamp_run(_78, _79)
    _81 = getattr(self, "prepack_folding._jit_pass_packed_weight_39")
    out10 = ops.prepacked.conv2d_clamp_run(_80, _81)
    _82 = torch._add_relu_(out10, _76, alpha=1)
    _83 = getattr(self, "prepack_folding._jit_pass_packed_weight_40")
    _84 = ops.prepacked.conv2d_clamp_run(_82, _83)
    _85 = getattr(self, "prepack_folding._jit_pass_packed_weight_41")
    _86 = ops.prepacked.conv2d_clamp_run(_84, _85)
    _87 = getattr(self, "prepack_folding._jit_pass_packed_weight_42")
    out11 = ops.prepacked.conv2d_clamp_run(_86, _87)
    _88 = torch._add_relu_(out11, _82, alpha=1)
    _89 = getattr(self, "prepack_folding._jit_pass_packed_weight_43")
    _90 = ops.prepacked.conv2d_clamp_run(_88, _89)
    _91 = getattr(self, "prepack_folding._jit_pass_packed_weight_44")
    _92 = ops.prepacked.conv2d_clamp_run(_90, _91)
    _93 = getattr(self, "prepack_folding._jit_pass_packed_weight_45")
    out12 = ops.prepacked.conv2d_clamp_run(_92, _93)
    _94 = torch._add_relu_(out12, _88, alpha=1)
    _95 = getattr(self, "prepack_folding._jit_pass_packed_weight_46")
    _96 = ops.prepacked.conv2d_clamp_run(_94, _95)
    _97 = getattr(self, "prepack_folding._jit_pass_packed_weight_47")
    _98 = ops.prepacked.conv2d_clamp_run(_96, _97)
    _99 = getattr(self, "prepack_folding._jit_pass_packed_weight_48")
    out13 = ops.prepacked.conv2d_clamp_run(_98, _99)
    _100 = torch._add_relu_(out13, _94, alpha=1)
    _101 = getattr(self, "prepack_folding._jit_pass_packed_weight_49")
    _102 = ops.prepacked.conv2d_clamp_run(_100, _101)
    _103 = getattr(self, "prepack_folding._jit_pass_packed_weight_50")
    _104 = ops.prepacked.conv2d_clamp_run(_102, _103)
    _105 = getattr(self, "prepack_folding._jit_pass_packed_weight_51")
    out14 = ops.prepacked.conv2d_clamp_run(_104, _105)
    _106 = torch._add_relu_(out14, _100, alpha=1)
    _107 = getattr(self, "prepack_folding._jit_pass_packed_weight_52")
    _108 = ops.prepacked.conv2d_clamp_run(_106, _107)
    _109 = getattr(self, "prepack_folding._jit_pass_packed_weight_53")
    _110 = ops.prepacked.conv2d_clamp_run(_108, _109)
    _111 = getattr(self, "prepack_folding._jit_pass_packed_weight_54")
    out15 = ops.prepacked.conv2d_clamp_run(_110, _111)
    _112 = torch._add_relu_(out15, _106, alpha=1)
    _113 = getattr(self, "prepack_folding._jit_pass_packed_weight_55")
    _114 = ops.prepacked.conv2d_clamp_run(_112, _113)
    _115 = getattr(self, "prepack_folding._jit_pass_packed_weight_56")
    _116 = ops.prepacked.conv2d_clamp_run(_114, _115)
    _117 = getattr(self, "prepack_folding._jit_pass_packed_weight_57")
    out16 = ops.prepacked.conv2d_clamp_run(_116, _117)
    _118 = torch._add_relu_(out16, _112, alpha=1)
    _119 = getattr(self, "prepack_folding._jit_pass_packed_weight_58")
    _120 = ops.prepacked.conv2d_clamp_run(_118, _119)
    _121 = getattr(self, "prepack_folding._jit_pass_packed_weight_59")
    _122 = ops.prepacked.conv2d_clamp_run(_120, _121)
    _123 = getattr(self, "prepack_folding._jit_pass_packed_weight_60")
    out17 = ops.prepacked.conv2d_clamp_run(_122, _123)
    _124 = torch._add_relu_(out17, _118, alpha=1)
    _125 = getattr(self, "prepack_folding._jit_pass_packed_weight_61")
    _126 = ops.prepacked.conv2d_clamp_run(_124, _125)
    _127 = getattr(self, "prepack_folding._jit_pass_packed_weight_62")
    _128 = ops.prepacked.conv2d_clamp_run(_126, _127)
    _129 = getattr(self, "prepack_folding._jit_pass_packed_weight_63")
    out18 = ops.prepacked.conv2d_clamp_run(_128, _129)
    _130 = torch._add_relu_(out18, _124, alpha=1)
    _131 = getattr(self, "prepack_folding._jit_pass_packed_weight_64")
    _132 = ops.prepacked.conv2d_clamp_run(_130, _131)
    _133 = getattr(self, "prepack_folding._jit_pass_packed_weight_65")
    _134 = ops.prepacked.conv2d_clamp_run(_132, _133)
    _135 = getattr(self, "prepack_folding._jit_pass_packed_weight_66")
    out19 = ops.prepacked.conv2d_clamp_run(_134, _135)
    _136 = torch._add_relu_(out19, _130, alpha=1)
    _137 = getattr(self, "prepack_folding._jit_pass_packed_weight_67")
    _138 = ops.prepacked.conv2d_clamp_run(_136, _137)
    _139 = getattr(self, "prepack_folding._jit_pass_packed_weight_68")
    _140 = ops.prepacked.conv2d_clamp_run(_138, _139)
    _141 = getattr(self, "prepack_folding._jit_pass_packed_weight_69")
    out20 = ops.prepacked.conv2d_clamp_run(_140, _141)
    _142 = torch._add_relu_(out20, _136, alpha=1)
    _143 = getattr(self, "prepack_folding._jit_pass_packed_weight_70")
    _144 = ops.prepacked.conv2d_clamp_run(_142, _143)
    _145 = getattr(self, "prepack_folding._jit_pass_packed_weight_71")
    _146 = ops.prepacked.conv2d_clamp_run(_144, _145)
    _147 = getattr(self, "prepack_folding._jit_pass_packed_weight_72")
    out21 = ops.prepacked.conv2d_clamp_run(_146, _147)
    _148 = torch._add_relu_(out21, _142, alpha=1)
    _149 = getattr(self, "prepack_folding._jit_pass_packed_weight_73")
    _150 = ops.prepacked.conv2d_clamp_run(_148, _149)
    _151 = getattr(self, "prepack_folding._jit_pass_packed_weight_74")
    _152 = ops.prepacked.conv2d_clamp_run(_150, _151)
    _153 = getattr(self, "prepack_folding._jit_pass_packed_weight_75")
    out22 = ops.prepacked.conv2d_clamp_run(_152, _153)
    _154 = torch._add_relu_(out22, _148, alpha=1)
    _155 = getattr(self, "prepack_folding._jit_pass_packed_weight_76")
    _156 = ops.prepacked.conv2d_clamp_run(_154, _155)
    _157 = getattr(self, "prepack_folding._jit_pass_packed_weight_77")
    _158 = ops.prepacked.conv2d_clamp_run(_156, _157)
    _159 = getattr(self, "prepack_folding._jit_pass_packed_weight_78")
    out23 = ops.prepacked.conv2d_clamp_run(_158, _159)
    _160 = torch._add_relu_(out23, _154, alpha=1)
    _161 = getattr(self, "prepack_folding._jit_pass_packed_weight_79")
    _162 = ops.prepacked.conv2d_clamp_run(_160, _161)
    _163 = getattr(self, "prepack_folding._jit_pass_packed_weight_80")
    _164 = ops.prepacked.conv2d_clamp_run(_162, _163)
    _165 = getattr(self, "prepack_folding._jit_pass_packed_weight_81")
    out24 = ops.prepacked.conv2d_clamp_run(_164, _165)
    _166 = torch._add_relu_(out24, _160, alpha=1)
    _167 = getattr(self, "prepack_folding._jit_pass_packed_weight_82")
    _168 = ops.prepacked.conv2d_clamp_run(_166, _167)
    _169 = getattr(self, "prepack_folding._jit_pass_packed_weight_83")
    _170 = ops.prepacked.conv2d_clamp_run(_168, _169)
    _171 = getattr(self, "prepack_folding._jit_pass_packed_weight_84")
    out25 = ops.prepacked.conv2d_clamp_run(_170, _171)
    _172 = torch._add_relu_(out25, _166, alpha=1)
    _173 = getattr(self, "prepack_folding._jit_pass_packed_weight_85")
    _174 = ops.prepacked.conv2d_clamp_run(_172, _173)
    _175 = getattr(self, "prepack_folding._jit_pass_packed_weight_86")
    _176 = ops.prepacked.conv2d_clamp_run(_174, _175)
    _177 = getattr(self, "prepack_folding._jit_pass_packed_weight_87")
    out26 = ops.prepacked.conv2d_clamp_run(_176, _177)
    _178 = torch._add_relu_(out26, _172, alpha=1)
    _179 = getattr(self, "prepack_folding._jit_pass_packed_weight_88")
    _180 = ops.prepacked.conv2d_clamp_run(_178, _179)
    _181 = getattr(self, "prepack_folding._jit_pass_packed_weight_89")
    _182 = ops.prepacked.conv2d_clamp_run(_180, _181)
    _183 = getattr(self, "prepack_folding._jit_pass_packed_weight_90")
    out27 = ops.prepacked.conv2d_clamp_run(_182, _183)
    _184 = torch._add_relu_(out27, _178, alpha=1)
    _185 = getattr(self, "prepack_folding._jit_pass_packed_weight_91")
    _186 = ops.prepacked.conv2d_clamp_run(_184, _185)
    _187 = getattr(self, "prepack_folding._jit_pass_packed_weight_92")
    _188 = ops.prepacked.conv2d_clamp_run(_186, _187)
    _189 = getattr(self, "prepack_folding._jit_pass_packed_weight_93")
    out28 = ops.prepacked.conv2d_clamp_run(_188, _189)
    _190 = torch._add_relu_(out28, _184, alpha=1)
    _191 = getattr(self, "prepack_folding._jit_pass_packed_weight_94")
    _192 = ops.prepacked.conv2d_clamp_run(_190, _191)
    _193 = getattr(self, "prepack_folding._jit_pass_packed_weight_95")
    _194 = ops.prepacked.conv2d_clamp_run(_192, _193)
    _195 = getattr(self, "prepack_folding._jit_pass_packed_weight_96")
    out29 = ops.prepacked.conv2d_clamp_run(_194, _195)
    _196 = getattr(self, "prepack_folding._jit_pass_packed_weight_97")
    identity2 = ops.prepacked.conv2d_clamp_run(_190, _196)
    _197 = torch._add_relu_(out29, identity2, alpha=1)
    _198 = getattr(self, "prepack_folding._jit_pass_packed_weight_98")
    _199 = ops.prepacked.conv2d_clamp_run(_197, _198)
    _200 = getattr(self, "prepack_folding._jit_pass_packed_weight_99")
    _201 = ops.prepacked.conv2d_clamp_run(_199, _200)
    _202 = getattr(self, "prepack_folding._jit_pass_packed_weight_100")
    out30 = ops.prepacked.conv2d_clamp_run(_201, _202)
    _203 = torch._add_relu_(out30, _197, alpha=1)
    _204 = getattr(self, "prepack_folding._jit_pass_packed_weight_101")
    _205 = ops.prepacked.conv2d_clamp_run(_203, _204)
    _206 = getattr(self, "prepack_folding._jit_pass_packed_weight_102")
    _207 = ops.prepacked.conv2d_clamp_run(_205, _206)
    _208 = getattr(self, "prepack_folding._jit_pass_packed_weight_103")
    out31 = ops.prepacked.conv2d_clamp_run(_207, _208)
    _209 = torch._add_relu_(out31, _203, alpha=1)
    _210 = torch.gt(torch.len(torch.size(_209)), 2)
    if _210:
      pass
    else:
      ops.prim.RaiseException("AssertionError: ")
    out32 = torch.adaptive_avg_pool2d(_209, [14, 14])
    encoder_out = torch.permute(out32, [0, 2, 3, 1])
    encoder_dim = torch.size(encoder_out, 3)
    encoder_out0 = torch.view(encoder_out, [1, -1, encoder_dim])
    num_pixels = torch.size(encoder_out0, 1)
    encoder_out1 = torch.expand(encoder_out0, [1, num_pixels, encoder_dim], implicit=False)
    complete_seqs = annotate(List[Tensor], [])
    complete_seqs_scores = annotate(List[float], [])
    mean_encoder_out = torch.mean(encoder_out1, [1], False, dtype=None)
    _211 = getattr(self, "prepack_folding._jit_pass_packed_weight_104")
    h = ops.prepacked.linear_clamp_run(mean_encoder_out, _211)
    _212 = getattr(self, "prepack_folding._jit_pass_packed_weight_105")
    c = ops.prepacked.linear_clamp_run(mean_encoder_out, _212)
    h0, c0, = (h, c)
    c1 = c0
    encoder_out2 = encoder_out1
    h1 = h0
    k = 1
    k_prev_words: Tensor = CONSTANTS.c0
    seqs: Tensor = CONSTANTS.c0
    step = 1
    top_k_scores: Tensor = CONSTANTS.c1
    _213 = True
    while _213:
      _214 = torch.embedding(CONSTANTS.c2, k_prev_words, -1, False, False)
      embeddings = torch.squeeze(_214, 1)
      _215 = getattr(self, "prepack_folding._jit_pass_packed_weight_106")
      att1 = ops.prepacked.linear_clamp_run(encoder_out2, _215)
      _216 = getattr(self, "prepack_folding._jit_pass_packed_weight_107")
      att2 = ops.prepacked.linear_clamp_run(h1, _216)
      _217 = torch._add_relu(att1, torch.unsqueeze(att2, 1), alpha=1)
      _218 = getattr(self, "prepack_folding._jit_pass_packed_weight_108")
      _219 = ops.prepacked.linear_clamp_run(_217, _218)
      att = torch.squeeze(_219, 2)
      alpha = torch.softmax(att, 1, None)
      _220 = torch.mul(encoder_out2, torch.unsqueeze(alpha, 2))
      attention_weighted_encoding = torch.sum(_220, [1], False, dtype=None)
      _221 = (attention_weighted_encoding, alpha)
      awe, _222, = _221
      _223 = getattr(self, "prepack_folding._jit_pass_packed_weight_109")
      _224 = ops.prepacked.linear_clamp_run(h1, _223)
      gate = torch.sigmoid(_224)
      awe0 = torch.mul(gate, awe)
      _225 = torch.cat([embeddings, awe0], 1)
      _226 = (h1, c1)
      _227 = torch.size(_225, 1)
      if torch.ne(_227, 2560):
        ops.prim.RaiseException(torch.format(_0, _227, 2560))
      else:
        pass
      _228 = (_226)[0]
      _229 = torch.size(_225, 0)
      _230 = torch.size(_228, 0)
      if torch.ne(_229, _230):
        _231 = torch.format(_1, _229, "[0]", _230)
        ops.prim.RaiseException(_231)
      else:
        pass
      _232 = torch.size(_228, 1)
      if torch.ne(_232, 512):
        _233 = torch.format(_2, "[0]", _232, 512)
        ops.prim.RaiseException(_233)
      else:
        pass
      _234 = (_226)[1]
      _235 = torch.size(_234, 0)
      if torch.ne(_229, _235):
        _236 = torch.format(_1, _229, "[1]", _235)
        ops.prim.RaiseException(_236)
      else:
        pass
      _237 = torch.size(_234, 1)
      if torch.ne(_237, 512):
        _238 = torch.format(_2, "[1]", _237, 512)
        ops.prim.RaiseException(_238)
      else:
        pass
      _239, _240, = _226
      _241, _242 = torch.lstm_cell(_225, [_239, _240], CONSTANTS.c3, CONSTANTS.c4, CONSTANTS.c5, CONSTANTS.c6)
      h2, c2, = (_241, _242)
      _243 = getattr(self, "prepack_folding._jit_pass_packed_weight_110")
      scores = ops.prepacked.linear_clamp_run(h2, _243)
      ret = torch.log_softmax(scores, 1, None)
      _244 = torch.expand_as(top_k_scores, ret)
      scores0 = torch.add(_244, ret, alpha=1)
      if torch.eq(step, 1):
        top_k_scores1, top_k_words0 = torch.topk(torch.select(scores0, 0, 0), k, 0, True, True)
        top_k_words, top_k_scores0 = top_k_words0, top_k_scores1
      else:
        top_k_scores2, top_k_words1 = torch.topk(torch.view(scores0, [-1]), k, 0, True, True)
        top_k_words, top_k_scores0 = top_k_words1, top_k_scores2
      prev_word_inds = torch.to(torch.div(top_k_words, 9490), 4, False, False, None)
      _245 = torch.remainder(top_k_words, 9490)
      next_word_inds = torch.to(_245, 4, False, False, None)
      _246 = annotate(List[Optional[Tensor]], [prev_word_inds])
      _247 = torch.index(seqs, _246)
      _248 = torch.unsqueeze(next_word_inds, 1)
      seqs0 = torch.cat([_247, _248], 1)
      incomplete_inds = annotate(List[int], [])
      _249 = torch.len(next_word_inds)
      _250 = ops.prim.min([9223372036854775807, _249])
      for ind in range(_250):
        next_word = torch.select(next_word_inds, 0, ind)
        if bool(torch.ne(next_word, 9489)):
          _251 = torch.append(incomplete_inds, ind)
        else:
          pass
      complete_inds = annotate(List[int], [])
      for i in range(_249):
        _252 = torch.__contains__(incomplete_inds, i)
        if torch.__not__(_252):
          _253 = torch.append(complete_inds, i)
        else:
          pass
      _254 = torch.gt(torch.len(complete_inds), 0)
      if _254:
        _255 = torch.tensor(complete_inds, dtype=4, device=None, requires_grad=False)
        _256 = annotate(List[Optional[Tensor]], [_255])
        _257 = torch.index(seqs0, _256)
        for _258 in range(torch.len(_257)):
          i0 = torch.select(_257, 0, _258)
          _259 = torch.append(complete_seqs, i0)
        _260 = torch.tensor(complete_inds, dtype=4, device=None, requires_grad=False)
        _261 = annotate(List[Optional[Tensor]], [_260])
        _262 = torch.index(top_k_scores0, _261)
        for _263 in range(torch.len(_262)):
          i1 = torch.select(_262, 0, _263)
          _264 = torch.append(complete_seqs_scores, float(torch.item(i1)))
      else:
        pass
      k0 = torch.sub(k, torch.len(complete_inds))
      if torch.eq(k0, 0):
        _265, _266, _267, _268, _269, _270, _271, _272, _273, _274, _275, _276, _277, _278, _279, _280, _281, _282, _283 = True, False, c2, encoder_out2, h2, k0, k_prev_words, seqs0, step, top_k_scores0, _5, _4, _4, _4, _3, _4, _4, _3, _4
      else:
        _284 = torch.tensor(incomplete_inds, dtype=4, device=None, requires_grad=False)
        _285 = annotate(List[Optional[Tensor]], [_284])
        seqs1 = torch.index(seqs0, _285)
        _286 = torch.tensor(incomplete_inds, dtype=4, device=None, requires_grad=False)
        _287 = annotate(List[Optional[Tensor]], [_286])
        _288 = torch.index(prev_word_inds, _287)
        _289 = annotate(List[Optional[Tensor]], [_288])
        h3 = torch.index(h2, _289)
        _290 = torch.tensor(incomplete_inds, dtype=4, device=None, requires_grad=False)
        _291 = annotate(List[Optional[Tensor]], [_290])
        _292 = torch.index(prev_word_inds, _291)
        _293 = annotate(List[Optional[Tensor]], [_292])
        c3 = torch.index(c2, _293)
        _294 = torch.tensor(incomplete_inds, dtype=4, device=None, requires_grad=False)
        _295 = annotate(List[Optional[Tensor]], [_294])
        _296 = torch.index(prev_word_inds, _295)
        _297 = annotate(List[Optional[Tensor]], [_296])
        encoder_out3 = torch.index(encoder_out2, _297)
        _298 = torch.tensor(incomplete_inds, dtype=4, device=None, requires_grad=False)
        _299 = annotate(List[Optional[Tensor]], [_298])
        _300 = torch.index(top_k_scores0, _299)
        top_k_scores3 = torch.unsqueeze(_300, 1)
        _301 = torch.tensor(incomplete_inds, dtype=4, device=None, requires_grad=False)
        _302 = annotate(List[Optional[Tensor]], [_301])
        _303 = torch.index(next_word_inds, _302)
        k_prev_words0 = torch.unsqueeze(_303, 1)
        _304 = torch.gt(step, 50)
        if _304:
          _305, _306, _307, _308, _309, _310, _311, _312, _313, _314, _315, _316, _317, _318, _319, _320, _321, _322 = False, c3, encoder_out3, h3, k0, k_prev_words0, seqs1, step, top_k_scores3, _5, _4, _4, _4, _3, _4, _4, _3, _4
        else:
          _305, _306, _307, _308, _309, _310, _311, _312, _313, _314, _315, _316, _317, _318, _319, _320, _321, _322 = _5, _4, _4, _4, _3, _4, _4, _3, _4, True, c3, encoder_out3, h3, k0, k_prev_words0, seqs1, torch.add(step, 1), top_k_scores3
        _265, _266, _267, _268, _269, _270, _271, _272, _273, _274, _275, _276, _277, _278, _279, _280, _281, _282, _283 = _304, _305, _306, _307, _308, _309, _310, _311, _312, _313, _314, _315, _316, _317, _318, _319, _320, _321, _322
      if _265:
        _323, _324, _325, _326, _327, _328, _329, _330, _331 = _266, _267, _268, _269, _270, _271, _272, _273, _274
      else:
        _323, _324, _325, _326, _327, _328, _329, _330, _331 = _275, _276, _277, _278, _279, _280, _281, _282, _283
      _213, c1, encoder_out2, h1, k, k_prev_words, seqs, step, top_k_scores = _323, _324, _325, _326, _327, _328, _329, _330, _331
    i2 = torch.index(complete_seqs_scores, ops.prim.max(complete_seqs_scores))
    return complete_seqs[i2]
